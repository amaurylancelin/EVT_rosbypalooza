{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from metpy.units import units\n",
    "from tqdm import tqdm\n",
    "from src.utils import compute_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all files in path \n",
    "# select var \n",
    "var = 'tas'\n",
    "sim_number = 0\n",
    "path = f\"/glade/derecho/scratch/awikner/PLASIM/data/2000_year_sims_new/sim{sim_number}/{var}/\"\n",
    "# select lat, lon and window size\n",
    "spatial_window_size = 2\n",
    "temporal_window_size = 7\n",
    "# Select lat and lon of Chicago\n",
    "lat = 41.881832\n",
    "lon = -87.623177 % 360 # for longitudes take the value modulo 360\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(path) if f.endswith('gaussian.nc')]\n",
    "files = files[:10]\n",
    "\n",
    "# disable the printing of the warning\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # combine all files using compute_A as a preprocessing function \n",
    "A = xr.open_mfdataset([path+file for file in files], preprocess=lambda ds: compute_A(ds, lat, lon, spatial_window_size, temporal_window_size), combine='nested',\n",
    "                       concat_dim='time', parallel=True, decode_times=True, use_cftime=True)\n",
    "\n",
    "# # combine all files using the compute_A as a preprocessing step #, add tqdm to see the progress\n",
    "# A = xr.concat([compute_A(xr.open_dataset(path + f), lat, lon, spatial_window_size, temporal_window_size) for f in tqdm(files)], dim='time')\n",
    "# A.to_netcdf(f'data/A_{var}_{int(lat)}_{int(lon)}_{spatial_window_size}_{temporal_window_size}.nc')\n",
    "\n",
    "A_df = A.to_dataframe()\n",
    "# save the dataframe\n",
    "A_df.to_csv(f'data/A_{var}_{int(lat)}_{int(lon)}_{spatial_window_size}_{temporal_window_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert index to pandas.DatetimeIndex\n",
    "# A_df = A.to_dataframe()\n",
    "\n",
    "# # select month 6, 7 or 8\n",
    "# A_df = A_df[np.isin(A_df.index.month, [6, 7, 8])]\n",
    "# A_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of A_df: 0.051605224609375 MB\n"
     ]
    }
   ],
   "source": [
    "path = \"/glade/work/alancelin/EVT_rossbypalooza/data/A_tas_41_272_2_7.csv\"\n",
    "A_df = pd.read_csv(path, index_col=0)\n",
    "print(f\"Memory usage of A_df: {A_df.memory_usage().sum() / 1024**2} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
