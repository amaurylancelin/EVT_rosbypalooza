{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43869c7-0a25-43a6-8309-d50e0e1de32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import src.evt\n",
    "import metpy.calc\n",
    "import metpy.units\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.patches as mpatches\n",
    "import cmocean\n",
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64455d04-a7a7-4303-aa40-ea5530032db5",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdaa7d6-fea7-41ce-a82e-9b3b4bfca191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whoi_data():\n",
    "    \"\"\"Load data originally obtained from WHOI's data server\"\"\"\n",
    "\n",
    "    ## open pre-computed PNW data\n",
    "    # data = xr.open_mfdataset(\"../data/*ure.nc\").compute()\n",
    "    data = xr.open_dataset(\"../data/whoi_data_US.nc\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_setup_simple(fig, projection, lon_range, lat_range):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_US(fig):\n",
    "    \"\"\"Plot Pacific region\"\"\"\n",
    "\n",
    "    ## Make projection\n",
    "    proj = ccrs.Orthographic(central_longitude=255, central_latitude=35)\n",
    "    # proj = ccrs.PlateCarree(central_longitude=240)\n",
    "    proj._threshold /= 1000\n",
    "    ax = plot_setup_simple(fig, proj, lon_range=[230, 290], lat_range=[15, 60])\n",
    "\n",
    "    ## Plot bartusek's box\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[-130, 40],\n",
    "            width=20,\n",
    "            height=20,\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=\"magenta\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            zorder=10,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mse(data):\n",
    "    \"\"\"compute moist static energy\"\"\"\n",
    "\n",
    "    ## get height\n",
    "    geopot = data[\"geopotential\"] * metpy.units.units(\"m^2/s^2\")\n",
    "    height = metpy.calc.geopotential_to_height(geopot)\n",
    "\n",
    "    ## add units to temp, humidity\n",
    "    temp = data[\"temperature\"] * metpy.units.units.kelvin\n",
    "    q = data[\"specific_humidity\"] * metpy.units.units(\"kg/kg\")\n",
    "\n",
    "    # compute MSE\n",
    "    mse = metpy.calc.moist_static_energy(\n",
    "        height=height, temperature=temp, specific_humidity=q\n",
    "    )\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adb5e2-4902-46d5-aca0-fa803c26f5bb",
   "metadata": {},
   "source": [
    "# Load and prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4665a-203d-4e67-9ff3-6c8921bdbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "data = load_whoi_data()\n",
    "\n",
    "## drop un-needed vars\n",
    "data = data.drop_vars([\"d2m\", \"sp\"]).metpy.dequantify()\n",
    "\n",
    "## Compute annual max\n",
    "data_annual_max = data.groupby(\"time.year\").max()\n",
    "year = data_annual_max.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610c661-332f-4620-ac02-06a6f99f176f",
   "metadata": {},
   "source": [
    "Function to compute return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1fc251e0-55f3-443a-bf57-7874883e0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tr_max(X):\n",
    "    \"\"\"estimate return period for maximum value w/ and w/o LOO training.\n",
    "    Function takes in a 1D np.array\"\"\"\n",
    "\n",
    "    ## Fit model and get return levels\n",
    "    bounds = dict(c=[-2, 2], loc=[200, 400], scale=[-1e2, 1e2])\n",
    "    \n",
    "    ## Get indices for \"Leave-one-out\" version of data\n",
    "    LOO_idx = np.array([i for i in range(len(X)) if i!=np.argmax(X)])\n",
    "    \n",
    "    ## fit models\n",
    "    kwargs = dict(model_class = scipy.stats.genextreme, bounds=bounds)\n",
    "    model = src.evt.fit_model(X, **kwargs)\n",
    "    model_LOO = src.evt.fit_model(X[LOO_idx], **kwargs)\n",
    "    \n",
    "    ## Get return periods for each model\n",
    "    Xr, tr = src.evt.get_return_levels(model, return_periods=np.logspace(0.01, 5, 100))\n",
    "    Xr_LOO, _ = src.evt.get_return_levels(model_LOO, return_periods=np.logspace(0.01, 5, 100))\n",
    "    \n",
    "    # ## Empirical return period\n",
    "    tr_empirical, Xr_empirical = src.evt.get_empirical_return_period(X)\n",
    "    \n",
    "    ## compute estimated return time for max event\n",
    "    tr_max = tr[np.argmin(np.abs(Xr_empirical[-1] - Xr))]\n",
    "    tr_max_LOO = tr[np.argmin(np.abs(Xr_empirical[-1] - Xr_LOO))]\n",
    "\n",
    "    return tr_max + 1j*tr_max_LOO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04700858-3d30-4027-9456-20938d36f8a9",
   "metadata": {},
   "source": [
    "#### Do the computation (slow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283a6b2-328c-47e4-9d28-75c3c42c8134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for T2m...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing for T2m...\")\n",
    "t1 = time.time()\n",
    "tr_max_t2m = xr.apply_ufunc(\n",
    "    get_tr_max, \n",
    "    data_annual_max[\"t2m\"], \n",
    "    input_core_dims=[[\"year\"]], \n",
    "    vectorize=True\n",
    ")\n",
    "t2 = time.time()\n",
    "print(f\"{t2-t1:.2f}\")\n",
    "\n",
    "## save to file\n",
    "tr_max_t2m.to_netcdf(pathlib.Path(os.environ['DATA_FP']) / \"tr_max_T2m.nc\")\n",
    "\n",
    "print(\"Computing for mse...\")\n",
    "t1 = time.time()\n",
    "tr_max_mse = xr.apply_ufunc(\n",
    "    get_tr_max, \n",
    "    data_annual_max[\"mse\"], \n",
    "    input_core_dims=[[\"year\"]], \n",
    "    vectorize=True\n",
    ")\n",
    "t2 = time.time()\n",
    "print(f\"{t2-t1:.2f}\")\n",
    "\n",
    "## save to file\n",
    "tr_max_mse.to_netcdf(pathlib.Path(os.environ['DATA_FP']) / \"tr_max_mse.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
